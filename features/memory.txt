## important_text
I am working on a project and this is my main.py file 
from Client import ai_response
import sys
import markdown
from PyQt5.QtWidgets import (
    QApplication,
    QWidget,
    QVBoxLayout,
    QTextBrowser,
    QTextEdit,
)
from PyQt5.QtCore import Qt, QObject, pyqtSignal, QThread
import html
import os

CUSTOM_CSS = """
<style>
.copy-button {
    color: #fff;
    cursor: pointer;
    border-radius: 5px;
    padding: 5px 10px;
}
body {
    font-family: 'Monaco', monospace;
    font-size: 14px;
    color: #e6e6e6;
    margin: 8px;
}
pre {
    background-color: #111;
    padding: 12px;
    border-radius: 6px;
    overflow-x: auto;
}
code {
    background-color: #111;
    color: #ddd;
    padding: 4px 6px;
    border-radius: 5px;
}
ul {
    padding-left: 25px;
}
</style>
"""

# Worker object that runs in a QThread and emits 'finished' when done.
# NOTE: finished now emits (query, result) so UI thread can persist both.
class AIWorker(QObject):
    finished = pyqtSignal(str, str)  # emits (query, output)

    def __init__(self, query):
        super().__init__()
        self.query = query

    def run(self):
        """Run in worker thread — call the blocking ai_response and emit result."""
        try:
            result = str(ai_response(self.query))
        except Exception as e:
            result = f"**Error:** {str(e)}"
        # Emit both query and result so main thread can write history properly
        self.finished.emit(self.query, result)


class CustomTextEdit(QTextEdit):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent

    def keyPressEvent(self, event):
        # Shift+Enter => newline, Enter => submit
        if event.modifiers() == Qt.ShiftModifier and event.key() == Qt.Key_Return:
            self.insertPlainText("\n")
        elif event.key() in (Qt.Key_Return, Qt.Key_Enter):
            # Delegate submit to parent (MainWindow)
            if self.parent:
                self.parent.handle_submit()
        else:
            super().keyPressEvent(event)


class MainWindow(QWidget):
    def __init__(self):
        super().__init__()

        self.setWindowTitle("Floating AI")
        self.resize(500, 400)

        self.layout = QVBoxLayout()
        self.setLayout(self.layout)

        self.output_display = QTextBrowser()
        self.output_display.setOpenLinks(False)
        self.layout.addWidget(self.output_display)

        self.text_input = CustomTextEdit(self)
        self.text_input.setFixedHeight(70)
        self.text_input.setFocus()
        self.text_input.setPlaceholderText("Type here...")
        self.layout.addWidget(self.text_input)

        # Keep references to current worker/thread so they are not GC'ed early
        self._worker_thread = None
        self._worker = None

        self.load_history()

    def set_markdown_output(self, output_display, md_text: str):
        # Convert Markdown to HTML and add custom CSS
        # Escape the text first to avoid accidental HTML injection from history
        # (we assume ai_response returns Markdown — still escape then run markdown to be safe)
        # If ai_response returns HTML already, you can skip the escaping step.
        safe_md = md_text
        try:
            # convert markdown to html
            html_content = markdown.markdown(safe_md, extensions=["fenced_code", "codehilite"])
        except Exception:
            # fallback: escape and wrap in <pre>
            html_content = f"<pre>{html.escape(safe_md)}</pre>"

        # Minimal copy button kept (QTextBrowser won't run JS)
        copy_button_html = """
        <div><button class="copy-button">Copy</button></div>
        """

        html_with_css = f"<html><head>{CUSTOM_CSS}</head><body>{copy_button_html}{html_content}</body></html>"
        output_display.setHtml(html_with_css)

    def analyze_text(self, text):
        """Analyze the text and decide if it's worth remembering."""
        # Define important keywords or phrases
        important_keywords = ["remember", "note", "important", "save", "store"]
        # Check if the text contains any important keywords
        lowered = text.lower()
        for keyword in important_keywords:
            if keyword in lowered:
                return True
        # Check if the text is a question or a significant declarative statement (heuristic)
        stripped = text.strip()
        if stripped.endswith("?") or len(stripped.split()) > 6:
            return True
        return False

    def save_to_memory(self, key, text):
        """Simple memory persistence: append to features/memory.txt with a key."""
        try:
            os.makedirs(os.path.dirname("features/memory.txt"), exist_ok=True)
        except Exception:
            pass
        try:
            with open("features/memory.txt", "a", encoding="utf-8") as f:
                f.write(f"## {key}\n{text}\n\n")
        except Exception:
            # Non-fatal: don't crash UI
            pass

    def load_memory(self):
        try:
            with open("features/memory.txt", "r", encoding="utf-8") as f:
                memory = f.read()
            if not memory.strip():
                return "**Memory is empty.**"
            return memory
        except FileNotFoundError:
            return "**Memory file not found.**"

    def clear_memory(self):
        try:
            with open("features/memory.txt", "w", encoding="utf-8") as f:
                f.write("")
        except Exception:
            pass

    def handle_submit(self):
        query = self.text_input.toPlainText().strip()
        if not query:
            return

        lower_q = query.lower()
        if lower_q == "exit":
            self.close()
            return

        if lower_q == "clear":
            self.output_display.clear()
            self.text_input.clear()
            return

        if lower_q == "clear history":
            try:
                with open("features/history.txt", "w", encoding="utf-8") as f:
                    f.write("")
            except Exception:
                pass
            self.load_history()
            self.text_input.clear()
            return

        if lower_q == "history":
            self.load_history()
            self.text_input.clear()
            return

        if lower_q == "memory":
            memory_content = self.load_memory()
            self.set_markdown_output(self.output_display, memory_content)
            self.text_input.clear()
            return

        if lower_q == "clear memory":
            self.clear_memory()
            self.set_markdown_output(self.output_display, "**Memory cleared successfully.**")
            self.text_input.clear()
            return

        if lower_q.startswith("set personality:"):
            # robust split — keep everything after the first colon
            parts = query.split(":", 1)
            if len(parts) > 1:
                personality_settings = parts[1].strip()
                try:
                    with open("features/personality.txt", "w", encoding="utf-8") as f:
                        f.write(personality_settings)
                    self.set_markdown_output(self.output_display, "**Personality settings saved successfully!**")
                except Exception:
                    self.set_markdown_output(self.output_display, "**Error saving personality.**")
            else:
                self.set_markdown_output(self.output_display, "**Error: No personality provided.**")
            self.text_input.clear()
            return

        # Optionally analyze and save short important notes to memory
        try:
            if self.analyze_text(query):
                self.save_to_memory("important_text", query)
                # don't interrupt user's flow — show a subtle notice
                # We'll still proceed to get an AI response
                # (If you prefer to *only* save and not query AI, return here)
        except Exception:
            pass

        # At this point: normal AI query — show loading, then launch worker thread
        self.set_markdown_output(self.output_display, "**Loading response...**")
        self.text_input.clear()

        # Create worker and thread
        worker = AIWorker(query)
        thread = QThread()

        # Move worker to thread and setup signals
        worker.moveToThread(thread)
        thread.started.connect(worker.run)
        # Connect finished(query, output) to handler
        worker.finished.connect(self.on_ai_response)  # UI update runs in main thread
        worker.finished.connect(thread.quit)
        worker.finished.connect(worker.deleteLater)
        thread.finished.connect(thread.deleteLater)

        # Keep references so they don't get GC'ed while running
        self._worker_thread = thread
        self._worker = worker

        thread.start()

    def on_ai_response(self, query: str, output: str):
        """Called in main thread via signal when worker finishes."""
        # Update the display and append to history
        self.set_markdown_output(self.output_display, output)
        try:
            # Append to history file (include the query)
            with open("features/history.txt", "a", encoding="utf-8") as f:
                f.write(f"**Query:** {query}\n{output}\n\n")
        except Exception:
            # Non-fatal — just don't crash the UI if history write fails
            pass

    def load_history(self):
        try:
            with open("features/history.txt", "r", encoding="utf-8") as f:
                history = f.read()
            if not history.strip():
                self.set_markdown_output(self.output_display, "**No conversation history found.**")
            else:
                self.set_markdown_output(self.output_display, history)
        except FileNotFoundError:
            self.set_markdown_output(self.output_display, "**No conversation history found.**")


if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec_())

this is my Client.py file 
# Imports
from groq import Groq
from dotenv import load_dotenv
import os

# Configuring API key
load_dotenv()
api_key = os.getenv("API_TOKEN")

# Client
client = Groq(
    api_key=api_key,
)

"""
USAGE:
To get response from the AI model

from Client import ai_response
user_query = input("Enter here: ")
output = ai_response(user_query)
print(output)
"""

RULES = """
You must strictly follow these rules for every response:

1. **Format**: Always respond in valid, well-structured Markdown.
2. **Clarity**: Use plain, simple language — avoid jargon unless defining it.
3. **Structure**: Organize with headers (#, ##), subheaders, bullet points, and numbered lists where helpful.
4. **Highlighting**: Use **bold** or *italic* for emphasis on important terms.
5. **Conciseness**: Keep answers to the point — no filler or repetition.
6. **Grammar & Tone**: Use correct grammar, spelling, punctuation, and maintain a consistent, professional, and friendly tone.
7. **Readability**: Use short paragraphs and line breaks for better flow.
8. **Examples**: Provide relevant examples, definitions, or tables when useful.
9. **Voice**: Use active voice instead of passive voice.
10. **Context**: Base your response on the provided chat history and personality settings.
11. **Focus**: Only answer the user’s query — no extra commentary or unrelated information.
"""

def get_personality():
    try:
        with open("features/personality.txt", "r") as f:
            return f.read()
    except:
        return ""

def get_chat_history():
    try:
        with open("features/history.txt", "r") as f:
            return f.read()
    except:
        return ""

def get_memory():
    try:
        with open("features/memory.txt", "r") as f:
            return f.read()
    except:
        return ""

def ai_response(user_query):
    personality = get_personality()
    chat_history = get_chat_history()
    memory = get_memory()

    prompt = f"""

Information you don't need to share with user until neccessary ->
{RULES}

Personality:
{personality}

Chat History:
{chat_history}

Memory:
{memory}

User Query:
{user_query}
"""

    chat_completion = client.chat.completions.create(
        messages=[
            {"role": "system", "content": "You are an AI assistant that follows rules exactly and outputs in Markdown."},
            {"role": "user", "content": prompt}
        ],
        model="llama-3.3-70b-versatile",
    )
    return chat_completion.choices[0].message.content

and this is my readme.md file

# Floating AI

Floating AI is a desktop application that utilizes the Groq API to provide AI-powered query responses. It features a user-friendly interface with interactive text input, Markdown-rendered AI responses, and keyboard shortcuts for efficient workflow.

---

## Features

- **AI-powered query responses using the Groq API**: Get instant answers to your questions with the help of the Groq API.  
- **Secure environment variable management with `.env`**: Store your API keys securely using environment variables.  
- **Interactive Text Input**: Type your queries or commands in the input box, which clears automatically after submission for a smooth workflow.  
- **Markdown-Rendered AI Responses**: View AI-generated replies with Markdown formatting, including headings, bold/italic text, bullet points, and code blocks.  

### Keyboard Shortcuts:
- **Enter/Return**: Submit query and get AI response instantly.  
- **Shift + Enter**: Insert a new line in the input box.  
- **Type `exit`**: Close the application gracefully.  
- **Type `clear`**: Clear the output display.  
- **Type `clear history`**: Clear the conversation history.  
- **Type `history`**: View the conversation history.

- **Copy Button**: Copy the AI output text to the clipboard with a single click.  

- **Integrated AI-memory**: The AI will remember previous conversations to avoid repetitive queries.  


---

## Upcoming Features

- **Custom Rules**: Set custom rules for the AI to tailor responses according to your preferences.  


---

## Installation

To run the application, ensure you have Python and the required libraries installed.  
You can install the libraries using:

```bash
pip install -r requirements.txt
python3 main.py 
```

### Basic Commands

| Key / Command   | Action                                           |
|-----------------|--------------------------------------------------|
| **Enter / Return** | Submit query and get AI response instantly.     |
| **Shift + Enter**  | Insert a new line in the input box.              |
| **F1**             | Copy AI output to clipboard.                    |
| **exit**           | Close the application gracefully.               |
| **clear**          | Clear the output display.                        |
| **clear history**  | Clear the conversation history.                  |
| **history**        | View the conversation history.                   |

---

## Demo
*(Insert a GIF or link to the demo here)*

---

## Authors
- **Your GitHub Username**

---

## Documentation
*(Add a link to detailed documentation if available)*

---

## Screenshots
*(Add screenshots or mockups of the UI here)*

---

## Optimizations
- Minimal resource usage with lightweight UI components.  
- Consistent coding style for easy maintainability.  
- Keyboard shortcuts for improved efficiency.  
- Secure `.env` file handling for API keys.  

---

## FAQ

**Q: How do I run the application?**  
A:  
```bash
python main.py
```
**Q: How do I clear the conversation history?**  
A: Type `clear history` in the input box to erase all stored queries and responses.

**Q: How do I view the conversation history?**  
A: Type `history` in the input box to display all past interactions in the output display.

**Q: How do I copy the AI output?**  
A: Press `F1` on your keyboard to instantly copy the latest AI response to your clipboard.

**Q: How do I close the application?**  
A: Type `exit` in the input box or press the `Esc` key.

---

## License
This project is licensed under the MIT License — see the [LICENSE](LICENSE) file for details.


Please modify my readme.md file and add everything as much as you can

